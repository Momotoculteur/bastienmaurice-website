## Hello ! 




![Photo de profil](../../../ressource/img/profile/photo.jpeg)

2 ans Fullstack Engineer - Thales<br>
2 ans DevOps Engineer - Thales<br>
2 ans+ Platform Engineer - Betclic<br>

</br></br>

**Et vous ?**


---



## Certification liste



![kubernetes-certification-path](./img/kubernetes-certification-path.png)

---



## Examen

- 60 questions Ã  choix multiples  
- 75â€¯% de bonnes rÃ©ponses requises  
- DurÃ©e : 90 minutes  
- Aucun point nÃ©gatif (pas de malus)  
- Certification valable 2 ans  
- 1 tentative de rattrapage autorisÃ©e



---



## Objectifs de la journÃ©e

- Comprendre Kubernetes, son architecture et ses fondamentaux
- Se familiariser avec lâ€™orchestration de conteneurs
- DÃ©couvrir lâ€™architecture Cloud Native et les bonnes pratiques
- Comprendre lâ€™observabilitÃ© et le delivery dans lâ€™Ã©cosystÃ¨me Kubernetes
- Se prÃ©parer Ã  la certification KCNA (Kubernetes & Cloud Native Associate)

</br></br>


| Domaine                           | % de l'examen | Temps allouÃ© |
| --------------------------------- | ------------- | ------------ |
| Kubernetes Fundamentals           | 46%           | 3h13         |
| Container Orchestration           | 22%           | 1h32         |
| Cloud Native Architecture         | 16%           | 1h07         |
| Cloud Native Observability        | 8%            | 34min        |
| Cloud Native Application Delivery | 8%            | 34min        |



---

# Kubernetes Fundamentals
#### Resources, Archi, API, Containers, Scheduling...

<!-- .slide: data-background="#009485" -->
<!-- .slide: class="center" -->


---


## Kubernetes - Historique & Cas dâ€™usage 

**ğŸ•°ï¸ Un peu dâ€™histoire**

- ğŸ§ª InspirÃ© de lâ€™outil interne de Google : **Borg**
- ğŸ“… Open source depuis 2014
- ğŸ¤ DonnÃ© Ã  la **CNCF** en 2015

</br></br>

**ğŸ§° Cas dâ€™usage courants**

- DÃ©ploiement dâ€™applications microservices
- CI/CD avec gestion automatisÃ©e des mises Ã  jour
- ScalabilitÃ© horizontale automatique
- Haute disponibilitÃ© et auto-rÃ©paration

</br></br>

ğŸ’¡ Kubernetes est devenu un **standard** de fait dans le cloud native ğŸŒ



---


## Architecture de Kubernetes - Control plane

Le **Control Plane** orchestre lâ€™Ã©tat global du cluster.

**ğŸ”§ Composants principaux**

- ğŸ§­ **kube-apiserver**  
  Point dâ€™entrÃ©e (REST API) â€“ communication centralisÃ©e.
- ğŸ“˜ **etcd**  
  Base de donnÃ©es clÃ©/valeur â€” Ã©tat du cluster.
- ğŸ§  **kube-scheduler**  
  Planifie les pods sur les nÅ“uds.
- ğŸ›¡ï¸ **kube-controller-manager**  
  GÃ¨re les boucles de contrÃ´le (daemonset, node, namespace...).
- ğŸ” **cloud-controller-manager** *(optionnel)*  
  IntÃ©gration cloud provider (load balancers, volumes...).

**ğŸ’¡ Fonctionnement :**

- Tu appliques un manifeste â†’ `kube-apiserver` lâ€™enregistre dans `etcd`.
- `scheduler` choisit un nÅ“ud â†’ `controller-manager` sâ€™assure que lâ€™Ã©tat voulu est atteint.
  


---



## Architecture de Kubernetes - Worker node

Chaque **Worker Node** exÃ©cute les pods applicatifs.

**ğŸ”© Composants principaux** 

- ğŸ§± **kubelet**  
  Agent qui communique avec le control plane.  
  â†’ ExÃ©cute les pods, assure leur santÃ©.
- ğŸ“¦ **container runtime**  
  Ex: `containerd`, `CRI-O`, `Docker`  
  â†’ Lance les conteneurs dÃ©finis dans les pods.
- ğŸŒ **kube-proxy**  
  GÃ¨re le rÃ©seau, le routage interne des services.

</br></br>

ğŸ“¦ **Les pods sont lancÃ©s ici**, pas sur le control plane !  
Chaque nÅ“ud est contrÃ´lÃ© par le scheduler et le control plane.


---



## Architecture de Kubernetes - SchÃ©ma



![kubernetes-control-and-worker-node](./img/kubernetes-control-and-worker-node.png)

---


## VMs vs Container - Rappels 

|             | **VM (Virtual Machine)** | **Container**                |
| ----------- | ------------------------ | ---------------------------- |
| OS inclus   | âœ… Oui (OS complet)       | âŒ Non (partage du noyau)     |
| DÃ©marrage   | ğŸ¢ Lent (minutes)         | âš¡ Rapide (secondes)          |
| Isolation   | ğŸ”’ Forte                  | ğŸ§© Plus lÃ©gÃ¨re                |
| Poids       | ğŸ“¦ Lourd (Go)             | ğŸª¶ LÃ©ger (Mo)                 |
| PortabilitÃ© | ğŸ” Moins portable         | ğŸŒ TrÃ¨s portable              |
| Cas d'usage | ğŸ¢ Legacy, multi-OS       | â˜ï¸ Microservices, cloud natif |

- Les conteneurs sont idÃ©aux pour des dÃ©ploiements rapides, reproductibles et efficaces
- Les VM restent utiles pour lâ€™isolation forte et les environnements hÃ©tÃ©rogÃ¨nes.




![vm-vs-container](./img/vm-vs-container.png)


---


## Docker & container - Rappels

**Quâ€™est-ce quâ€™un conteneur ?**  

- Un **environnement isolÃ©** pour exÃ©cuter une application  
- Contient tout ce quâ€™il faut : code, librairies, dÃ©pendances  
- LÃ©ger, rapide Ã  dÃ©marrer âš¡  
- Identique en dev, test, prod ğŸ“¦

</br></br>

**Docker ğŸ”§**  

- Plateforme la plus populaire pour **crÃ©er, exÃ©cuter et gÃ©rer des conteneurs**  
- Utilise une image comme **modÃ¨le** pour lancer des conteneurs  
- Commandes clÃ©s :

```bash
docker build -t monapp .
docker run -p 8080:80 monapp
docker ps
```

</br></br>

ğŸ’¡ Kubernetes orchestre les conteneurs crÃ©Ã©s avec Docker ou d'autres runtimes comme containerd



---


## KubeCTL

UtilisÃ© pour interagir avec l'API Server de Kube

**ğŸ’¡ Tips**
- `kubectl get pods` â†’ voir les pods
- `kubectl describe pod mon-pod` â†’ dÃ©tails
- `kubectl delete -f mon-fichier.yaml` â†’ suppression

</br></br>

**Commandes disponible** 

- annotation  
- **apply**  
- auth
- autoscale
- cp
- **create**
- **delete**
- **describe**



---



## Exemple de manifeste YAML (Pod)

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: mon-pod
spec:
  containers:
    - name: nginx
      image: nginx:latest
```

```bash
kubectl apply -f mon-fichier.yaml
```

</br></br>

- Envoie un **fichier manifeste** au serveur Kubernetes.
- Kubernetes **interprÃ¨te** le YAML pour crÃ©er/modifier la ressource dÃ©clarÃ©e.



---



## Pods â€“ L'unitÃ© de base dans Kubernetes

- Plus petite unitÃ© dÃ©ployable dans Kubernetes  
- Contient un ou plusieurs **conteneurs** partageant le mÃªme rÃ©seau et stockage  
- Cycle de vie liÃ©, s'exÃ©cutent sur un **Node** du cluster

**CaractÃ©ristiques**  

- Partage dâ€™IP et de ports entre les conteneurs du Pod ğŸŒ  
- Ã‰phÃ©mÃ¨re : les Pods peuvent Ãªtre recrÃ©Ã©s, remplacÃ©s, mais ne sont pas persistants  
- GÃ©rÃ© par des contrÃ´leurs comme **Deployment**, **ReplicaSet**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: example-pod
spec:
  containers:
  - name: nginx-container
    image: nginx:latest
```

</br>

ğŸ’¡ Les Pods sont la **brique de base** sur laquelle Kubernetes construit des applications complexes



---



## Replicaset â€“ Maintien du nombre de Pods

- Ressource Kubernetes qui garantit un **nombre fixe de Pods** en fonctionnement  
- CrÃ©e ou supprime des Pods pour correspondre au nombre dÃ©sirÃ©  
- Assure la haute disponibilitÃ© des applications

**Fonctionnement**  

- Utilise un **label selector** pour gÃ©rer les Pods ciblÃ©s  
- **DÃ©ployÃ© gÃ©nÃ©ralement via un Deployment** (rarement seul)

```yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: myapp-replicaset
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: myapp-container
        image: nginx:latest
```

</br>
ğŸ’¡ ReplicaSet assure la rÃ©silience en maintenant toujours le bon nombre de Pods



---


## Deployments â€“ Gestion des applications

- Ressource Kubernetes qui gÃ¨re le **dÃ©ploiement et la mise Ã  jour** des Pods  
- Assure le nombre dÃ©sirÃ© de rÃ©plicas disponibles ğŸ”„  
- Permet le **rolling update** sans interruption de service  

**FonctionnalitÃ©s clÃ©s**  

- Scaling automatique ou manuel ğŸ“ˆğŸ“‰  
- Rollback automatique en cas dâ€™erreur âª  
- StratÃ©gies de mise Ã  jour (RollingUpdate, Recreate)

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: myapp-container
        image: nginx:latest
```

ğŸ’¡ Deployments simplifient la gestion du cycle de vie des applications dans Kubernetes



---



## Probes

**Liveness Probe**

- VÃ©rifie si le **conteneur est vivant**  
- Si KO âœ le conteneur est **redÃ©marrÃ©**  
- Exemple : boucle infinie ou process bloquÃ©

**Readiness Probe**

- VÃ©rifie si le conteneur est **prÃªt Ã  recevoir du trafic**  
- Si KO âœ **retirÃ©** du Service  
- Exemple : temps d'initialisation long â³

**Startup Probe**

- VÃ©rifie si l'application a **bien dÃ©marrÃ©**  
- Utile pour Ã©viter que liveness redÃ©marre trop tÃ´t ğŸš«  
- Une fois OK âœ les deux autres probes prennent le relais

```yaml
livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
```

ğŸ’¡ Les probes assurent la **stabilitÃ© et la fiabilitÃ©** de vos applications dans Kubernetes ğŸ”„


---



## Selecteur, Labels & Annotations

**ğŸ·ï¸ Labels â€“ pour sÃ©lectionner & organiser**  

- **Paires clÃ©/valeur** attachÃ©es aux objets Kubernetes  
- UtilisÃ©s pour la **sÃ©lection** (ex : par un Service, ReplicaSet...)  
```yaml
labels:
  app: frontend
  tier: web
```

â¡ï¸ Permet de cibler un groupe dâ€™objets via `kubectl` ou des sÃ©lecteurs

</br>

**ğŸ“ Annotations â€“ pour ajouter du contexte** 

- Aussi des **paires clÃ©/valeur**, mais **non utilisÃ©es pour la sÃ©lection**  
- Utiles pour stocker des **mÃ©tadonnÃ©es** : version, checksum, info CI/CD, etc.  
```yaml
annotations:
  git-commit: "abc123"
  maintainer: "dev@exemple.com"
```

Labels = pour **filtrer & organiser** ğŸ§©  
Annotations = pour **documenter sans impacter le comportement** ğŸ—’ï¸




---



## Stateless vs Stateful 

**Stateless**  

- Pas de conservation dâ€™Ã©tat entre les requÃªtes  
- Chaque requÃªte est indÃ©pendante  
- Facile Ã  scaler horizontalement  
- Exemple : serveur web statique, API REST sans session

</br>

**Stateful**  

- Conservation dâ€™Ã©tat entre les requÃªtes  
- NÃ©cessite gestion de la session ou des donnÃ©es persistantes  
- Plus complexe Ã  scaler et Ã  gÃ©rer  
- Exemple : base de donnÃ©es, applications avec session utilisateur

</br></br>

ğŸ’¡ Kubernetes favorise les workloads **stateless**, mais supporte aussi les **stateful** via StatefulSets, PV, PVC


---



## Namespaces - Isolation & Organisation

- Espace virtuel pour **isoler et organiser** les ressources Kubernetes  
- Permet de gÃ©rer plusieurs environnements ou Ã©quipes sur un mÃªme cluster   
- Les noms des ressources sont uniques **dans un namespace** (pas globalement)

</br></br>

**UtilitÃ©s**  

- SÃ©parer dev, test, prod  
- Appliquer des politiques RBAC diffÃ©rentes   
- Limiter les ressources consommÃ©es par namespace 

```bash
kubectl get namespaces
kubectl create namespace mon-projet
```

</br></br>

ğŸ’¡ Les namespaces facilitent la **gestion multi-tenant** et la sÃ©curitÃ© dans Kubernetes ğŸ”„

---



## Services 

- Permettent dâ€™exposer des **Pods** de maniÃ¨re stable (mÃªme si les Pods changent)
- Assurent la **dÃ©couverte de services** via DNS interne
- Fournissent un **load balancing interne** ğŸ”„

**ğŸ¯ Types de Services**

- **ClusterIP** (par dÃ©faut) : accÃ¨s interne au cluster  
- **NodePort** : accÃ¨s externe via un port sur chaque nÅ“ud  
- **LoadBalancer** : provisionne un load balancer cloud  
- **ExternalName** : redirige vers un nom DNS externe  


ğŸ’¡ Un Service dÃ©couple les clients de la complexitÃ© des Pods ğŸ§©
```yaml
apiVersion: v1
kind: Service
metadata:
  name: myservice
spec:
  selector:
    app: myapp
  ports:
    - port: 80
      targetPort: 80
```

Client ---> [Service] ---> [Pods avec les bons labels]  
          (IP stable)       (IPs dynamiques)




---



## Volumes 

- Espace de stockage **montÃ© dans un pod**  
- Permet de **persister les donnÃ©es** au-delÃ  du cycle de vie du conteneur  
- Types variÃ©s : `emptyDir`, `hostPath`, `configMap`, `secret`, `persistentVolumeClaim`, etc.

**âš™ï¸ Fonctionnement**

- DÃ©clarÃ© dans le spec du pod  
- UtilisÃ© par un ou plusieurs conteneurs via un **mountPath**  
- Garantit la disponibilitÃ© des donnÃ©es durant lâ€™exÃ©cution du pod

**ğŸ“ Exemple simple avec `emptyDir`**  

```yaml
volumes:
- name: cache-volume
  emptyDir: {}
containers:
- name: app
  image: busybox
  volumeMounts:
  - mountPath: /cache
    name: cache-volume
```

ğŸ’¡ Les volumes sont essentiels pour gÃ©rer la **durabilitÃ© des donnÃ©es** dans Kubernetes



---


## Persistent Volumes

- Ressource **abstraite** reprÃ©sentant un espace de stockage dans le cluster  
- CrÃ©Ã©e **manuellement** ou **automatiquement** via une StorageClass  
- UtilisÃ©e via un `PersistentVolumeClaim` (PVC)

**ğŸ”„ Cycle de vie**  

- **Available** â†’ Libre  
- **Bound** â†’ AttachÃ© Ã  un PVC  
- **Released** â†’ LibÃ©rÃ© mais pas encore rÃ©utilisable  
- **Failed** â†’ Erreur

```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-example
spec:
  capacity:
    storage: 1Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: "/mnt/data"
```

ğŸ’¡ PV = ressource physique ou virtuelle de **stockage durable**, indÃ©pendante du pod


---


## Persistent Volume Claim

**ğŸ“Œ Quâ€™est-ce quâ€™un PVC ?**

- RequÃªte de **stockage persistant** par un utilisateur ou une application  
- Demande un volume avec une capacitÃ© et des caractÃ©ristiques spÃ©cifiques  
- Lie un Pod Ã  un **Persistent Volume (PV)** disponible

**ğŸ§© Fonctionnement**  

- Kubernetes cherche un PV compatible (capacity, accessModes, storageClass)  
- Une fois trouvÃ©, le PV est **bindÃ©** au PVC  
- Le Pod utilise ensuite le PVC pour accÃ©der au stockage

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-example
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
  storageClassName: fast-ssd
```

ğŸ’¡ PVC = interface utilisateur pour demander du stockage persistant dans Kubernetes


--- 


## Storage Class

**ğŸ“¦ Quâ€™est-ce quâ€™une StorageClass ?** 

- DÃ©finit **le type de stockage dynamique** utilisable par les volumes  
- UtilisÃ©e pour provisionner automatiquement un `PersistentVolume` (PV) Ã  partir dâ€™un `PersistentVolumeClaim` (PVC)

**ğŸ§° ParamÃ¨tres possibles**  

- Type de provisioner (ex: `kubernetes.io/aws-ebs`, `csi`)  
- ReclaimPolicy : `Retain`, `Delete`, `Recycle`  
- AccessModes : `ReadWriteOnce`, `ReadOnlyMany`, `ReadWriteMany`  
- `allowVolumeExpansion`: true/false

```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: fast-ssd
provisioner: kubernetes.io/aws-ebs
parameters:
  type: gp2
```

ğŸ’¡ Le PVC choisit une `StorageClass` pour demander un **stockage adaptÃ© et automatisÃ©**


---



## RBAC et sÃ©curitÃ© de base

**ğŸ‘¤ ServiceAccounts**  

- IdentitÃ© utilisÃ©e par les **pods** pour sâ€™authentifier auprÃ¨s de lâ€™API Kubernetes  
- MontÃ©e automatiquement dans les pods (`/var/run/secrets/...`)  
- Par dÃ©faut : `default` dans chaque namespace  
â¡ï¸ Utiliser des comptes dÃ©diÃ©s pour les apps sensibles

**ğŸ›¡ï¸ RBAC (Role-Based Access Control)** 

- ContrÃ´le **qui peut faire quoi** sur quelles ressources  
- Principaux objets :
  - `Role` / `ClusterRole` : ensemble de permissions  
  - `RoleBinding` / `ClusterRoleBinding` : association dâ€™une identitÃ© Ã  un rÃ´le


ğŸ’¡ ğŸ§  Combinez **ServiceAccount + RBAC** pour sÃ©curiser les accÃ¨s applicatifs

```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: default
  name: pod-reader
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "watch", "list"]
```



---


## Exemple : Role + RoleBinding

Donner accÃ¨s en lecture aux **Secrets** du namespace `dev` Ã  un pod utilisant le `ServiceAccount: reader`

```yaml
# Role : permissions locales
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: read-secrets
  namespace: dev
rules:
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["get", "list"]
```

```yaml
# RoleBinding : attribution Ã  une identitÃ©
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: bind-read-secrets
  namespace: dev
subjects:
- kind: ServiceAccount
  name: reader
roleRef:
  kind: Role
  name: read-secrets
  apiGroup: rbac.authorization.k8s.io
```

---


## Exemple : ClusterRole + ClusterRoleBinding

Donner accÃ¨s en lecture Ã  **tous les pods du cluster** Ã  un `ServiceAccount` nommÃ© `auditor`

```yaml
# ClusterRole : permissions globales
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: read-all-pods
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "watch"]
```

```yaml
# ClusterRoleBinding : attribution globale
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: bind-read-all-pods
subjects:
- kind: ServiceAccount
  name: auditor
  namespace: default
roleRef:
  kind: ClusterRole
  name: read-all-pods
  apiGroup: rbac.authorization.k8s.io
```


---



## Kubernetes distributions

**â˜ï¸ Cloud-managed**  

- **GKE** (Google Kubernetes Engine)  
- **EKS** (Elastic Kubernetes Service â€“ AWS)  
- **AKS** (Azure Kubernetes Service)  
â¡ï¸ GÃ©rÃ©s par les fournisseurs cloud, intÃ©grÃ©s Ã  leurs services

**ğŸ—ï¸ On-premise & DIY**  

- **kubeadm** : installation manuelle, flexible  
- **RKE** : Rancher Kubernetes Engine  
- **MicroK8s**, **Minikube**, **k3s** : lÃ©gers, idÃ©als pour dev/test

**ğŸ§© Autres distributions populaires**  

- **RedHat OpenShift** : Kubernetes + outils CI/CD, monitoring, sÃ©curitÃ© intÃ©grÃ©e (SELinux,APPArmor...)
- **VMware Tanzu**, **Canonical Charmed K8s**, etc.




---



## Questions : Kubernetes Fundamentals

1. Quel composant stocke l'Ã©tat du cluster ?
2. Quelle est la diffÃ©rence entre un Pod et un Deployment ?
3. Quel type de Service dois-je utiliser pour exposer publiquement un Pod ?
4. Quelle commande permet d'appliquer un fichier YAML ?



---

# Container Orchestration 
#### Container, Runtime, Security, Networking, Service mesh, Storage...

<!-- .slide: data-background="#009485" -->
<!-- .slide: class="center" -->


---


## Runtime 

- Logiciel responsable de **lâ€™exÃ©cution des conteneurs** sur chaque nÅ“ud  
- Interface entre Kubernetes (via **kubelet**) et le systÃ¨me dâ€™exploitation

**ğŸ”„ CompatibilitÃ© avec Kubernetes**  

- Kubernetes utilise le standard **Container Runtime Interface (CRI)**  
- Permet dâ€™utiliser diffÃ©rents runtimes conformes :  

| Runtime                            | Langage      | Statut        | ParticularitÃ©s                                                                                                 |
| ---------------------------------- | ------------ | ------------- | -------------------------------------------------------------------------------------------------------------- |
| **containerd**                     | Go           | ğŸ”¥ RecommandÃ© | LÃ©ger, stable, maintenu par la CNCF. UtilisÃ© par dÃ©faut par Kubernetes via `kubelet`.                          |
| **CRI-O**                          | Go           | âœ… Stable      | Minimaliste, conÃ§u spÃ©cifiquement pour Kubernetes et 100 % compatible avec CRI. UtilisÃ© par Red Hat/OpenShift. |
| **Docker (dockershim)**            | Go           | âŒ DÃ©prÃ©ciÃ©    | Docker a longtemps Ã©tÃ© utilisÃ©, mais **n'est plus supportÃ©** directement par Kubernetes depuis v1.24.          |
| **gVisor**                         | Go/C         | âœ… Stable      | Sandbox avec isolation accrue (Google). Moins performant mais plus sÃ©curisÃ©.                                   |
| **Kata Containers**                | Rust/C       | âœ… Stable      | Chaque conteneur tourne dans une VM lÃ©gÃ¨re. TrÃ¨s sÃ©curisÃ©.                                                     |
| **Wasmtime / runwasi**             | Rust         | ğŸ§ª En test    | Permet dâ€™exÃ©cuter du WebAssembly (WASM) Ã  la place des conteneurs classiques.                                  |
| **MirageOS / Nabla / Firecracker** | OCaml / Rust | ExpÃ©rimentaux | Runtimes ultra-lÃ©gers et sÃ©curisÃ©s pour des cas trÃ¨s spÃ©cifiques (IoT, serverless, etc.)                       |


**ğŸ“¦ RÃ´le du runtime**  

- TÃ©lÃ©charger les images  
- CrÃ©er, exÃ©cuter, stopper et supprimer les conteneurs  
- GÃ©rer les volumes et le rÃ©seau


---



## Helm

**ğŸ“¦ Quâ€™est-ce que Helm ?**  
**Gestionnaire de packages Kubernetes**  
Permet dâ€™installer, configurer et maintenir des applications via des **charts**

**ğŸ§© Concepts clÃ©s**  

- **Chart** : ensemble de fichiers YAML modÃ©lisant une app (templates + valeurs)  
- **Values.yaml** : fichier de configuration personnalisable  
- **Release** : instance dÃ©ployÃ©e dâ€™un chart

**ğŸš€ Commandes utiles**  
```bash
helm repo add bitnami https://charts.bitnami.com/bitnami
helm install myapp bitnami/nginx
helm upgrade myapp bitnami/nginx --set service.type=NodePort
```

ğŸ’¡ Helm = gain de temps, rÃ©utilisabilitÃ©, dÃ©ploiements propres & reproductibles



---

![what-is-helm-package-manage](./img/what-is-helm-package-manage.png)

---


## Kustomize 

- Outil natif Kubernetes pour **personnaliser les manifests YAML**  
- Permet de crÃ©er des variantes sans dupliquer les fichiers  
- BasÃ© sur une approche **patch & overlay**

</br></br>

**FonctionnalitÃ©s clÃ©s** 

- Ajout/modification de labels, annotations  
- Fusion ou remplacement de champs dans les manifests  
- Gestion de plusieurs environnements (dev, staging, prod) facilement  

</br></br>

ğŸ’¡ Kustomize facilite la **gestion dÃ©clarative** et la rÃ©utilisation des configurations Kubernetes


---



## Kustomize - Exemple

```bash
myapp/
â”œâ”€â”€ base/
â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â””â”€â”€ kustomization.yaml
â””â”€â”€ overlays/
    â””â”€â”€ prod/
        â”œâ”€â”€ kustomization.yaml
        â””â”€â”€ patch.yaml
```

```bash
# base/deploy.yaml
apiVersion: apps/v1
kind: Deployment
spec:
  replicas: 1
```

```bash
# base/kustomization.yaml
resources:
  - deployment.yaml
```

```bash
# overlays/prod/patch.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  replicas: 3
```

```bash
# overlays/prod/kustomization.yaml
resources:
  - ../../base
patchesStrategicMerge:
  - patch.yaml
```



---



## Jobs 

- ExÃ©cutent une **tÃ¢che unique** jusquâ€™Ã  rÃ©ussite  
- UtilisÃ©s pour des traitements batch, migrations, scripts dâ€™initialisation  
- GÃ©rÃ©s automatiquement (relances si Ã©chec)

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: hello-job
spec:
  template:
    spec:
      containers:
      - name: hello
        image: busybox
        command: ["echo", "Hello KCNA!"]
      restartPolicy: Never
  backoffLimit: 3
```



---


## CronJobs

- Planifient des **Jobs Ã  intervalles rÃ©guliers**  
- Syntaxe similaire Ã  `cron` (ex: `0 * * * *`)  
- Exemples : sauvegardes, envois rÃ©currents, tÃ¢ches de nettoyage

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: hello-cronjob
spec:
  schedule: "*/5 * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: hello
            image: busybox
            command: ["echo", "Hello every 5 minutes!"]
          restartPolicy: OnFailure
```


---



## Autoscaling des Pods

Permet d'ajuster Ã  la demande, sans aucune intervention manuelle, les ressources en CPU/RAM  

S'adapte selon le traffic users, selon des rÃ¨gles & events

</br>

**Horizontal Pod Autoscaler (HPA)**  

- Ajuste automatiquement le nombre de pods en fonction de mÃ©triques (CPU, mÃ©moire, custom)  
- Permet de gÃ©rer la charge variable sans intervention manuelle  

**Vertical Pod Autoscaler (VPA)**  

- Ajuste automatiquement les ressources (CPU, mÃ©moire) allouÃ©es aux pods  
- Optimise les performances sans changer le nombre de pods  
- âš ï¸ Ne scale pas le nombre de pods, seulement les ressources allouÃ©es.
- âš ï¸ Requiert souvent des redÃ©marrages de pods â†’ impact potentiel sur la disponibilitÃ©.




---



## Autoscaling des Nodes

**Cluster Autoscaler (CA)**  

- Ajuste automatiquement le nombre de nÅ“uds du cluster selon la charge  
- Supprime les nÅ“uds inutilisÃ©s pour optimiser les coÃ»ts  

**Karpenter**  

- Autoscaler dynamique et intelligent, dÃ©veloppÃ© par AWS  
- Optimise la planification des nÅ“uds, rapide et flexible  
- Supporte divers fournisseurs cloud et configurations

ğŸ’¡ **Autoscaling global = meilleure disponibilitÃ© et maÃ®trise des coÃ»ts**



---



## Serverless & Function as a Service (FaaS)

**Quâ€™est-ce que le Serverless ?**  

- ExÃ©cution de code sans gÃ©rer lâ€™infrastructure serveur  
- Facturation Ã  lâ€™usage (par invocation ou durÃ©e dâ€™exÃ©cution)  
- Auto-scalabilitÃ© automatique

**Function as a Service (FaaS)**  

- Micro-fonctions lÃ©gÃ¨res dÃ©clenchÃ©es par des Ã©vÃ©nements  
- Exemple : AWS Lambda, Azure Functions, Google Cloud Functions

**OpenFaaS**  

- Plateforme FaaS open-source pour Kubernetes  
- DÃ©ploiement simple de fonctions en conteneurs  
- IntÃ©gration facile avec Kubernetes, auto-scaling inclus  
- Supporte multiples langages et frameworks

ğŸ’¡ Serverless simplifie le dÃ©ploiement et la gestion dâ€™applications Ã©vÃ©nementielles



---



## Open Standards

**Quâ€™est-ce quâ€™un Open Standard ?**  

- Norme **ouverte et publique**, accessible Ã  tous  
- DÃ©veloppÃ©e et maintenue par une communautÃ© ou un organisme indÃ©pendant  
- Favorise lâ€™interopÃ©rabilitÃ© entre diffÃ©rents systÃ¨mes et fournisseurs

</br></br>

**Pourquoi câ€™est important ?** 

- Ã‰vite la **dÃ©pendance propriÃ©taire** (vendor lock-in)  
- Facilite la collaboration et lâ€™intÃ©gration  
- Assure la pÃ©rennitÃ© et lâ€™Ã©volution des technologies



---


## Open Standards - Exemple

**Exemples dans Kubernetes & Cloud Native** 

- **OpenTelemetry** : standard dâ€™instrumentation et de tÃ©lÃ©mÃ©trie  
- **OCI** (Open Container Initiative) : Format standard des images et la maniÃ¨re dont les conteneurs doivent Ãªtre exÃ©cutÃ©s (docker, podman, buildah)
- **CNI** (Container Networking Interface) : Standards ppour connecter les pods Ã  un rÃ©seau, gÃ¨re lâ€™allocation dâ€™IP, la configuration rÃ©seau, le routage, etc (calico, cilium)
- **CRI** (Container Runtime Interface) : Standards entre Kubernetes et le runtime de conteneur, permet Ã  k8s de lancer des conteneurs sans dÃ©pendre de Docker (containerd, cri-o)

</br></br>

ğŸ’¡ Utiliser des standards ouverts favorise un Ã©cosystÃ¨me robuste et flexible



---



## Custom Resource Definitions (CRDs)

**ğŸ”§ Extension de lâ€™API Kubernetes**  

- Permettent de **dÃ©finir de nouveaux types de ressources** personnalisÃ©es  
- Facilite lâ€™ajout de fonctionnalitÃ©s spÃ©cifiques sans modifier le cÅ“ur Kubernetes

</br></br>

**ğŸŒŸ Exemples courants**  

- **cert-manager** : gestion automatisÃ©e des certificats SSL/TLS  
- **Prometheus Operator** : gestion simplifiÃ©e des instances Prometheus  

</br></br>

ğŸ’¡ **Les CRDs ouvrent la voie Ã  un Kubernetes extensible et adaptable aux besoins mÃ©tiers !**

```yaml
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: monitoring.coreos.com/v1
```



---



## Questions : Orchestration

1. Qu'est-ce qu'un chart Helm ?
2. DiffÃ©rence entre Job et CronJob ?
3. Pourquoi utiliser un CRD ?



---


# Cloud Native Architecture

<!-- .slide: data-background="#009485" -->
<!-- .slide: class="center" -->
---



## Microservices VS Monolitique - DÃ©finition

|                    | **Monolithe**                     | **Microservices**               |
|--------------------|----------------------------------|--------------------------------|
| Architecture       | Application unique, tout-en-un   | Application dÃ©coupÃ©e en services indÃ©pendants |
| DÃ©ploiement        | Un seul dÃ©ploiement global       | DÃ©ploiements indÃ©pendants par service          |
| ScalabilitÃ©        | ScalabilitÃ© globale (tout ou rien) | ScalabilitÃ© ciblÃ©e par service                  |
| Maintenance        | Complexe et risquÃ©e               | Plus simple, services isolÃ©s                     |
| Technologies       | Une seule stack souvent           | PossibilitÃ© dâ€™utiliser plusieurs stacks         |
| RÃ©silience         | DÃ©fauts impactent toute lâ€™app    | Isolation des pannes limitÃ©e Ã  un service        |

ğŸ’¡ **Le microservice favorise agilitÃ©, Ã©volutivitÃ© et rÃ©silience, clÃ©s du Cloud Native !**



---



## ConfigMaps

- Stockent les **configurations non sensibles** (fichiers de config, variables dâ€™environnement)  
- SÃ©parent la configuration du code â†’ facilite les mises Ã  jour sans redÃ©ployer lâ€™app  
- Doivent rester **lisibles** et non sensibles  

</br></br>

ğŸ’¡ **Astuce :** utiliser des volumes ou variables dâ€™environnement pour injecter ConfigMaps/Secrets dans les pods en Ã©vitant la duplication.

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: mon-configmap
  namespace: default
data:
  APP_ENV: "production"
  APP_DEBUG: "false"
  DATABASE_URL: "postgres://user:pass@db:5432/ma_db"
```





---


## Secrets

- Stockent les **informations sensibles** (mots de passe, clÃ©s API, certificats)  
- EncodÃ©s en Base64, mais **pas chiffrÃ©s** par dÃ©faut â†’ utiliser un gestionnaire externe pour plus de sÃ©curitÃ© (ex: Vault)  
- Limiter lâ€™accÃ¨s aux secrets via les **RBAC**  

ğŸ’¡ **Astuce :** utiliser des volumes ou variables dâ€™environnement pour injecter ConfigMaps/Secrets dans les pods en Ã©vitant la duplication.

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: mon-secret
  namespace: default
type: Opaque
data:
  DB_USER: dXNlcg==       # "user" encodÃ© en base64
  DB_PASSWORD: cGFzc3dvcmQ=  # "password" encodÃ© en base64
```



---



## Service Mesh

**Principaux outils**  

- Istio, Linkerd

**Fonctions clÃ©s**  

- ğŸ”€ **Routage** avancÃ© du trafic entre services  
- ğŸ“Š Collecte de **mÃ©triques** fines au niveau service  
- ğŸ” SÃ©curitÃ© renforcÃ©e via **mTLS** (mutual TLS)  
- Ne modifie pas le code des applications

</br></br>

ğŸ’¡ **BÃ©nÃ©fices** : visibilitÃ©, contrÃ´le et sÃ©curitÃ© renforcÃ©e pour les communications inter-services.



---



## Questions : Architecture

1. Quelle est la responsabilitÃ© d'un Service Mesh ?
2. Quelle diffÃ©rence entre Secret et ConfigMap ?
3. Quel composant rend un conteneur stateless ?



---


# Cloud Native Observability
#### Telemetry, Prom, Cost management...

<!-- .slide: data-background="#009485" -->
<!-- .slide: class="center" -->
---



## Prometheus & Grafana

**â¬‡ï¸ Prometheus**  

- RÃ©cupÃ©ration des mÃ©triques par **pull**  
- Stockage et requÃªtage des donnÃ©es mÃ©triques  
- SystÃ¨me dâ€™**alerting** intÃ©grÃ©  

**ğŸ“ˆ Grafana**  

- CrÃ©ation de **dashboards** visuels personnalisÃ©s  
- Visualisation en temps rÃ©el des mÃ©triques et alertes  
- Supporte plusieurs sources de donnÃ©es  

ğŸ’¡ **Objectif Cloud Native** : surveillance proactive et analyse visuelle centralisÃ©e !





![grafana-dashboard](./img/grafana-dashboard.png)


---



## Logging et Tracing

**ğŸ“š Logging**

- **Fluentd**, **Loki** : collecte, centralisation et recherche des logs  
- Logs essentiels pour le debug et monitoring

**ğŸ•µï¸â€â™‚ï¸ Tracing**

- **Jaeger** : suivi des requÃªtes distribuÃ©es  
- Analyse des performances et goulots dâ€™Ã©tranglement

**ğŸ“ OpenTelemetry**

- Standard ouvert dâ€™instrumentation  
- Unifie collecte de mÃ©triques, logs, traces

</br></br>

ğŸ’¡ **Focus Cloud Native** : observabilitÃ© complÃ¨te pour diagnostiquer efficacement !



---



## Questions : ObservabilitÃ©

1. Quelle est la diffÃ©rence entre Prometheus et Grafana ?
2. Quel outil permet de centraliser les logs ?
3. Quel protocole est utilisÃ© pour les traces distribuÃ©es ?



---

# Cloud Native Application Delivery
#### Apps fundamentals, GitOps, CI/CD...kcna 
<!-- .slide: data-background="#009485" -->
<!-- .slide: class="center" -->

---



## CI/CD et GitOps

**ğŸ”§ CI/CD (IntÃ©gration & DÃ©ploiement continus)**

- **Jenkins**, **GitLab CI** : automatisent build, tests, dÃ©ploiement
- Pipelines dÃ©crits sous forme de fichiers (`Jenkinsfile`, `.gitlab-ci.yml`)

</br></br>

**ğŸŒ¿ GitOps**

- DÃ©ploiement **dÃ©claratif** via Git (source de vÃ©ritÃ©)
- Ex : **ArgoCD**, **FluxCD**
- Suivi des changements via Git â†’ synchronisation automatique avec le cluster

</br></br>

ğŸ’¡ **Objectif Cloud Native** : automatiser, versionner et sÃ©curiser les dÃ©ploiements !




---



## SÃ©curitÃ© de livraison 

**ğŸš¦ Admission Controllers**  

- ContrÃ´lent et valident les requÃªtes API avant leur application  
- Permettent dâ€™imposer des politiques de sÃ©curitÃ©, conformitÃ©, bonnes pratiques  
  
**1. Built-in Admission Controllers**
| Nom                   | RÃ´le                                                      |
| --------------------- | --------------------------------------------------------- |
| **NamespaceLifecycle**  | EmpÃªche de crÃ©er des objets dans des namespaces supprimÃ©s |
| **LimitRanger**         | Implique des limites de CPU/mÃ©moire par dÃ©faut            |
| **DefaultStorageClass** | Assigne une StorageClass si absente                       |

**2. Dynamic Admission Controllers (Webhooks)**  

ğŸ“Œ Mutating Admission Webhook

- Peut modifier la requÃªte (ex. injection automatique de sidecar Istio)
- ExÃ©cutÃ© avant validation

ğŸ“Œ Validating Admission Webhook

- Peut refuser ou valider la requÃªte
- ExÃ©cutÃ© aprÃ¨s mutation

| Ã‰lÃ©ment                     | Description                                                       |
| --------------------------- | --------------------------------------------------------------    |
| **Admission Controller** | Plugin de lâ€™API Server, mutateur ou validateur                     |
| **Built-in**             | ActivÃ© cÃ´tÃ© kube-apiserver (ex: LimitRanger)                       |
| **Webhook**              | Service HTTP/HTTPS externe, flexible (ex: OPA Gatekeeper, Kyverno) |




---


## SÃ©curitÃ© de livraison 

**ğŸ›¡ï¸ OPA & Gatekeeper**  

- **OPA (Open Policy Agent)**
  - Câ€™est un moteur de dÃ©cision gÃ©nÃ©raliste basÃ© sur un langage de policy : Rego.
  - Tu lui envoies des donnÃ©es, il renvoie une dÃ©cision (allow, deny, etc.).
- **Gatekeeper**
  - IntÃ¨gre OPA en tant que moteur de policy (controller)
  - GÃ¨re les rÃ¨gles et contraintes via des CRDs
  - Se comporte comme un Validating Admission Webhook

```yaml
apiVersion: constraints.gatekeeper.sh/v1beta1
kind: K8sRequiredLabels
metadata:
  name: require-team-label
spec:
  match:
    kinds:
      - apiGroups: [""]
        kinds: ["Pod"]
  parameters:
    labels: ["team"]
```
â†’ Cela refuse tous les pods qui ne dÃ©clarent pas metadata.labels.team.



---


## SÃ©curitÃ© de livraison 

**ğŸ” Scan dâ€™images**  

- **Trivy**, **Snyk** : dÃ©tectent vulnÃ©rabilitÃ©s, failles de sÃ©curitÃ© dans les images conteneurs  
- IntÃ©gration possible dans pipelines CI/CD pour blocage prÃ©coce  

</br></br>

ğŸ’¡ **But : garantir la sÃ©curitÃ© et la conformitÃ© avant dÃ©ploiement en production !**



---



## Questions : Delivery

1. Qu'est-ce que GitOps ?
2. Quelle est la diffÃ©rence entre un pipeline CI et CD ?
3. Quel outil permet de scanner une image de conteneur ?



---

# CNCF
#### Structure, memberships, boards...

<!-- .slide: data-background="#009485" -->
<!-- .slide: class="center" -->

---


## CNCF â€“ Cloud Native Computing Foundation

Fondation sous la Linux Foundation  
Soutient lâ€™Ã©cosystÃ¨me **Cloud Native**  
Accueille des projets comme Kubernetes, Prometheus...  

</br></br>

**Gouvernance structurÃ©e** 
- ğŸ“œ **Governing Board** (stratÃ©gie & finance)
- ğŸ§  **Technical Oversight Committee (TOC)** (feuille de route technique)
- ğŸ› ï¸ **Special Interest Groups (SIGs)** (groupes dâ€™experts thÃ©matiques)

</br></br>

| Structure              | Niveau                  | RÃ´le principal                         | ResponsabilitÃ©s clÃ©s                                                 | Membres typiques                      |
| ---------------------- | ----------------------- | -------------------------------------- | -------------------------------------------------------------------- | ------------------------------------- |
| ğŸ“œ **Governing Board** | StratÃ©gique             | Vision, stratÃ©gie, financement         | Budgets, partenariats, dÃ©cisions juridiques, croissance du projet    | ReprÃ©sentants des entreprises membres |
| ğŸ§  **TOC**             | Technique (stratÃ©gique) | Supervision technique globale          | Feuille de route, cohÃ©rence des projets, validation technique        | Experts techniques Ã©lus ou nommÃ©s     |
| ğŸ› ï¸ **SIGs**           | OpÃ©rationnel            | Travail technique ciblÃ© sur un domaine | DÃ©veloppement, maintenance, revue de code, support aux contributeurs | Mainteneurs, dÃ©veloppeurs             |



---



## CNCF â€“ Governing Board

**ğŸ¯ RÃ´le**  

Le Governing Board est lâ€™instance dÃ©cisionnelle stratÃ©gique et financiÃ¨re dâ€™un projet ou dâ€™une fondation.


**âš™ï¸ ResponsabilitÃ©s principales**  

- DÃ©finir la stratÃ©gie globale (vision, expansion, partenariats)
- Allouer les budgets (marketing, Ã©vÃ©nements, dÃ©veloppement, sÃ©curitÃ©, etc.)
- GÃ©rer les relations avec les sponsors, membres fondateurs, et partenaires
- Superviser les aspects juridiques et contractuels
- Valider ou influencer les grandes dÃ©cisions comme :
  - Lâ€™admission de nouveaux projets dans la fondation
  - Les changements de licence
  - Les dÃ©penses exceptionnelles

**ğŸ‘¥ Composition**  

GÃ©nÃ©ralement constituÃ© de reprÃ©sentants des entreprises membres (ex : Platinum Members dans la CNCF) ou dâ€™Ã©lus.



---


## CNCF â€“ Technical Oversight Committee (TOC)

**ğŸ¯ RÃ´le**  

Le TOC est le garant de la cohÃ©rence technique du projet ou de lâ€™Ã©cosystÃ¨me soutenu par la fondation.

**âš™ï¸ ResponsabilitÃ©s principales**  

- DÃ©finir la feuille de route technique
- Ã‰valuer les projets candidats Ã  une incubation ou graduation (ex. dans la CNCF : Envoy, Prometheus, OpenTelemetryâ€¦)
- Maintenir la cohÃ©rence architecturale entre les projets
- Piloter les bonnes pratiques, les exigences de sÃ©curitÃ©, dâ€™interopÃ©rabilitÃ©, de documentationâ€¦
- Ã‰valuer les projets abandonnÃ©s ou obsolÃ¨tes

**ğŸ‘¥ Composition**  

Des experts techniques indÃ©pendants, souvent Ã©lus ou nommÃ©s par leurs pairs. Ils ont une vision neutre et long terme.



---


## CNCF â€“ Special Interest Groups (SIGs)

**ğŸ¯ RÃ´le**  

Les SIGs sont des groupes de travail thÃ©matiques. Ils opÃ¨rent au plus prÃ¨s du code et des usages.

**âš™ï¸ ResponsabilitÃ©s principales**  

- GÃ©rer une sous-partie technique du projet ou un domaine fonctionnel spÃ©cifique (ex : SIG Networking, SIG Security, SIG Observabilityâ€¦)
- Proposer des amÃ©liorations, rÃ©diger des Kubernetes Enhancement Proposals (KEP) ou Ã©quivalents
- Revoir du code, proposer des APIs, expÃ©rimenter des features
- Servir de point dâ€™entrÃ©e pour les contributeurs
- Participer Ã  la documentation, tests et intÃ©gration continue

**ğŸ‘¥ Composition**  

Ouverts Ã  tous les contributeurs  
MenÃ©s par des mainteneurs ou leads, souvent nommÃ©s par mÃ©rite  
Fonctionnent via des rÃ©unions rÃ©guliÃ¨res, Slack, mailing lists, GitHubâ€¦  



---


## CNCF Tech Radar

- Publication communautaire (trimestrielle)
- Classe les technologies selon lâ€™adoption :
  - âœ… **Adopt**
  - ğŸ”¬ **Trial**
  - ğŸ§ª **Assess**
  - ğŸš« **Hold**

**Objectif** 

- Aider les Ã©quipes Ã  comprendre les tendances rÃ©elles
- Donne une **vue concrÃ¨te** sur ce qui marche en production

ğŸ“Š BasÃ© sur des retours de membres du End User Community



---



## CNCF Memberships

**Types** 

- ğŸ¥‡ **Platinum**
  - 1 personne admise au Governing Board
- ğŸ¥ˆ **Gold**
  - 1 personne admise au Governing Board pour 5 members (max 3)
- ğŸ¥‰ **Silver**
  - 1 personne admise au Governing Board pour 1O members (max 3)
- ğŸ‘¨â€ğŸ« **Academic / Nonprofit institution**

**Avantages** 

- VisibilitÃ© dans la communautÃ©
- Droit de vote au Governing Board (selon le niveau)
- Influence sur la feuille de route CNCF

ğŸ’¡ Plus de 160 membres, dont Google, Red Hat, Microsoft...


---



## Quizz - Examen blanc



---



## Conseils de prÃ©paration

- ğŸ¯ **60 questions gratuites** disponibles sur [app.exampro.co](https://app.exampro.co)  
- ğŸ’¸ **SÃ©ries supplÃ©mentaires** disponibles sur Udemy (payantes)
- â±ï¸ **EntraÃ®ne-toi au rythme rÃ©el** : ~1min30 par question  
  â†’ Ne reste pas bloquÃ© trop longtemps
- ğŸ’¡ **Se mÃ©fier des piÃ¨ges de vocabulaire**  
  Lire attentivement chaque proposition.



---



**ğŸ“ Concepts fondamentaux**

- Quâ€™est-ce quâ€™un cluster Kubernetes ?
- Architecture : Control Plane vs Workers
- Principales ressources : Pod, Service, Deployment, ConfigMap, Secret

**âš™ï¸ Outils CLI**

- `kubectl` : commandes de base (`get`, `describe`, `logs`, `apply`, `delete`)
- Notions de contexte (`kubectl config use-context`)

**ğŸ“¦ Conteneurs & images**

- Docker / containerd / OCI
- Fichier Dockerfile & `docker build`

**ğŸŒ RÃ©seau & Services**

- ClusterIP, NodePort, LoadBalancer
- DNS interne, communication entre pods

**â˜ï¸ Ã‰cosystÃ¨me CNCF**

- Open source, projets CNCF (Prometheus, Helm, etc.)
- CNCF Landscape et notions de Cloud Native

